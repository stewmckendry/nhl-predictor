# ğŸ““ AI-Native Delivery Framework: Phase 2 Enhancements (April 2025)

## ğŸ“Š Purpose

This document captures the next evolution of the AI-Native Delivery System, focused on reducing friction, improving traceability, and accelerating project execution for the NHL Predictor PoC and future AI-native projects.

The goal is to build upon the strong foundations already in place, enhancing the system to be more seamless, automated, repeatable, and auditable.

---

# ğŸ”¢ Why Are We Enhancing the Framework?

| Problem | Impact |
|:--------|:-------|
| Too many manual steps | Slows delivery, introduces errors |
| Rigid promote_patch after every micro-task | Overhead, no batching |
| Fragile prompt handling | Blockers when prompts missing |
| Poor chain-of-thought capture | No visibility into how Pods reasoned |
| Manual reasoning traces and handoffs | High human burden |
| Risky memory.yaml drift | Sync issues without structure |


---

# âœ¨ Future State Vision

| Area | Future Behavior | Outcome |
|:-----|:----------------|:--------|
| Task execution | Activate â†’ auto-update â†’ auto-commit | Fast, fluid task progress |
| Prompt management | Auto-draft prompts, auto-store and commit prompts | No blockers, full traceability |
| Reasoning trace | Auto-generate reasoning aligned with metrics framework | Full auditability, structured reasoning |
| Git commits | Auto-commit major lifecycle updates | Clean history, no micromanagement |
| Promote_patch | Batch promote only meaningful milestones | Strategic, lightweight promotions |
| Chain of Thought | Append reasoning evolution automatically | Human-AI collaboration visible |
| Changelog | Central CHANGELOG.md updated automatically | Clear audit trails |
| Handoff notes | Auto-generate and appendable per task | Seamless Pod transitions |
| Metrics | Integrated reasoning capture, CoT linkage | Improved system learning |
| Project initialization | Repo setup + framework standardization automated | Fast, consistent starting point |


---

# ğŸ”§ Implementation Plan

## ğŸ“Š New FastAPI Routes

| Route | Purpose |
|:------|:--------|
| `/project/init_project` | Create + initialize new project repo |
| `/tasks/append_chain_of_thought/{task_id}` | Append to chain of thought file |
| `/tasks/auto_commit/{task_id}` | Auto-commit minor updates to Git |
| `/tasks/append_handoff_note/{task_id}` | Append or create handoff note |
| `/tasks/append_changelog` | Auto-update CHANGELOG.md entries |


## ğŸ“Š OpenAPI Schema Updates

- `/tasks/activate` â†’ Document smart prompt fallback
- Add schemas for new endpoints above
- Confirm promote_patch aligns to new batch promotion logic


## ğŸ“Š New Scripts

| Script | Purpose |
|:-------|:--------|
| `scripts/structure_repo.py` | Set up repo scaffolding for projects |
| `scripts/auto_commit.py` | Auto-commit minor updates |
| `scripts/append_chain_of_thought.py` | Append step notes to chain of thought files |
| `scripts/append_handoff_note.py` | Auto-create or update handoff notes |
| `scripts/append_changelog.py` | Add structured entries to CHANGELOG.md |


## ğŸ“Š Prompt and Template Updates

| Item | Change |
|:-----|:------|
| DeliveryPod system prompt | Auto-call append_chain_of_thought at key events |
| Project templates | Add `/outputs/`, `/scripts/`, `/templates/` directories |
| Reasoning trace | Align with structured format for metrics capture |


## ğŸ“Š Memory.yaml / Task.yaml Updates

- Link `prompt_used.txt`, `reasoning_trace.md`, `cot.md`, and `handoff.md` to each task if available
- Track `project_init_trace` for project initialization steps


## ğŸ“Š Auto-Commit Logic

| Event | Auto-Commit? |
|:------|:------------|
| Task activated | âœ… |
| Task completed | âœ… |
| Prompt drafted due to missing file | âœ… |
| Reasoning trace updated | âœ… |
| Chain of thought appended | âœ… |
| Handoff note updated | âœ… |
| Minor metadata tweak | âŒ (batch later)


## ğŸ“Š Chain of Thought Capture

- Chain of thought file `/outputs/task_updates/{task_id}/cot_{task_id}.md`
- Appended automatically at key reasoning events (activation, updates, pivots)


## ğŸ“Š Prompt Management

- Auto-draft missing prompts during `/tasks/activate`
- Auto-save prompts to correct path and commit
- Link prompt to memory.yaml


## ğŸ“Š Reasoning Trace Management

- Auto-generate reasoning trace aligned with metrics framework
- Use chain of thought log to enrich reasoning trace
- Save under `/outputs/task_updates/{task_id}/reasoning_trace.md`


## ğŸ“Š Changelog Management

- Central `CHANGELOG.md` updated automatically
- Every tool that commits changes will also append a structured entry to the changelog.
- Avoid using separate explicit API calls; integrate changelog updates directly into tool handlers for best practice.


## ğŸ“Š Handoff Notes

- Auto-generate `.logs/handoff/{task_id}_handoff.md` per task
- Allow appending via GPT or Human Lead
- Linked optionally in memory.yaml


## ğŸ“Š Promote_Patch Best Practices

- Human Lead triggers promote_patch after logical milestones (e.g., finish Discovery Phase)
- promote_patch bundles updates, generates changelog, and creates PR


## ğŸ“Š Auto-Commit Upgrades to Existing Routes

| Route | Enhancement |
|:------|:------------|
| `/tasks/activate` | After updating task status, save prompt if missing, auto-commit `task.yaml`, append to changelog |
| `/tasks/create` | After creating new task, auto-commit `task.yaml`, append to changelog |
| `/tasks/update_metadata/{task_id}` | If significant fields updated (done, prompt, etc.), auto-commit `task.yaml`, append to changelog |
| `/tasks/clone` | After cloning, auto-commit updated `task.yaml`, append to changelog |
| `/memory/index` | After reindexing, auto-commit `memory.yaml`, append to changelog |
| `/memory/add` | After adding new memory entries, auto-commit `memory.yaml`, append to changelog |


## ğŸ“Š Master Checklist for Execution

- [ ] Implement `/project/init_project`
- [ ] Implement `/tasks/append_chain_of_thought/{task_id}`
- [ ] Implement `/tasks/auto_commit/{task_id}`
- [ ] Implement `/tasks/append_handoff_note/{task_id}`
- [ ] Auto-capture prompts on `/tasks/activate`
- [ ] Auto-capture reasoning trace aligned with metrics framework
- [ ] Auto-append chain of thought entries
- [ ] Auto-update CHANGELOG.md on all commits
- [ ] Auto-generate handoff notes on task completion
- [ ] Update OpenAPI schemas accordingly
- [ ] Align DeliveryPod system prompts with new flows
- [ ] Test full end-to-end cycle from init to promote_patch


---

# ğŸš€ End-to-End Examples

## A) Project Initialization
**Human Lead:**
- Triggers `/project/init_project` with repo details and project metadata.

**GPT Pod Tools:**
- Scaffold repo structure.
- Fetch or create `task.yaml` and `memory.yaml`.
- Capture and save initial prompt and reasoning.
- Auto-commit to GitHub (`chatgpt/auto/init_project`).


## B) Discovery Tasks (1.1 Capture Goals, 1.2 User Flows)
**GPT Pod:**
- Calls `/tasks/activate` for each task.
- Auto-drafts missing prompt if needed.
- Captures prompt_used.txt, reasoning_trace.md, and appends to cot.md.
- Auto-commits "in_progress" and "done" status changes.

**Human Lead:**
- Monitors Pod output.
- Optionally reviews and updates drafts.
- After multiple tasks complete, calls `promote_patch` manually to formalize batch updates.


## C) Development Tasks (2.1 Design, 2.2 Build Feature)
**GPT Pod:**
- Activates each development task via `/tasks/activate`.
- Produces designs, code, documentation.
- Captures full prompt/reasoning trace automatically.
- Auto-commits after meaningful deliverables.

**Human Lead:**
- Reviews outputs as needed.
- Ensures logical batches (e.g., full feature) before triggering `promote_patch`.


---


# ğŸ“‰ Final Words

This enhancement phase will:
- Maximize delivery speed
- Minimize friction
- Maximize traceability
- Scale Pods easily
- Preserve full auditable context

Let's build on our strong foundation and take AI-Native delivery to the next level! âœ¨ğŸš€

---
---

# ğŸ”§ Prioritized Implementation Backlog

The implementation will proceed in **batches**, aligned with the AI-native SDLC phases. After each batch, we will test using the NHL Predictor PoC to ensure the model enhancements are functioning as intended.


## ğŸ”¹ Batch 1: Project Initialization Phase

| Step | Action |
|:-----|:------|
| 1.1 | Implement `/project/init_project` route and logic |
| 1.2 | Create `scripts/structure_repo.py` to scaffold repo |
| 1.3 | Capture and auto-commit initial prompt and reasoning |
| 1.4 | Initialize memory.yaml links for project context |
| 1.5 | Update system prompt for project init process |


## ğŸ”¹ Batch 2: Discovery Phase (Early Task Execution)

| Step | Action |
|:-----|:------|
| 2.1 | Implement `/tasks/activate` smart prompt fallback |
| 2.2 | Implement auto-capture of prompt_used.txt |
| 2.3 | Implement auto-capture of reasoning_trace.md |
| 2.4 | Implement `/tasks/append_chain_of_thought/{task_id}` |
| 2.5 | Implement `/tasks/auto_commit/{task_id}` functionality |
| 2.6 | Wire auto-commit into activate/create/clone routes |
| 2.7 | Begin wiring changelog updates into these tool handlers |


## ğŸ”¹ Batch 3: Development Phase (Ongoing Task Execution)

| Step | Action |
|:-----|:------|
| 3.1 | Implement `/tasks/update_metadata/{task_id}` auto-commit |
| 3.2 | Implement `/tasks/clone` auto-commit |
| 3.3 | Enable auto-save of interim deliverables (designs, docs) |
| 3.4 | Auto-update chain of thought during development cycles |
| 3.5 | Continue wiring changelog updates for all dev actions |


## ğŸ”¹ Batch 4: Testing Phase (E2E Task Execution)

| Step | Action |
|:-----|:------|
| 4.1 | Implement `/memory/index` auto-commit |
| 4.2 | Implement `/memory/add` auto-commit |
| 4.3 | Add test capture of e2e readiness in reasoning traces |
| 4.4 | Expand system prompts for e2e validation behaviors |
| 4.5 | Test full traceable task flows in NHL PoC |


## ğŸ”¹ Batch 5: Cutover and Go-Live Phase

| Step | Action |
|:-----|:------|
| 5.1 | Implement `/tasks/append_handoff_note/{task_id}` route |
| 5.2 | Formalize handoff notes per task on completion |
| 5.3 | Finalize full batch promote_patch with complete artifacts |
| 5.4 | Validate CHANGELOG.md end-to-end capture |
| 5.5 | Validate memory.yaml coherence |
| 5.6 | Publish final NHL Predictor PoC app and system audit trail |

## ğŸ”¹ Batch 6: Final System Polish and Hardening

| Step | Action |
|:-----|:------|
| 6.1 | Define rollback strategy for failed batch deployments |
| 6.2 | Integrate metrics instrumentation into reasoning traces |
| 6.3 | Create short Human Lead onboarding guide for new flows |
| 6.4 | Explore multi-Pod orchestration options (stretch goal) |

---

# ğŸ”§ Thoughts and Confirmations

âœ… This model will:
- Implement foundational enhancements progressively.
- Test practical flows after each major functional upgrade.
- Deliver both the framework AND the NHL PoC app working seamlessly.

âœ… Every major SDLC phase will be tested and verified before moving forward.

âœ… Risk is minimized by validating at each phase rather than all at once.


# ğŸš€ Ready to Queue Up First Batch?

Batch 1 (Project Initialization Phase) is scoped and ready to begin!

Let's proceed to define the tasks in Batch 1 in detail and kick off the work. ğŸ’¡

---


# ğŸ““ AI-Native Delivery Framework: Phase 2 Enhancements (April 2025)

## ğŸ“Š Purpose

This document captures the next evolution of the AI-Native Delivery System, focused on reducing friction, improving traceability, and accelerating project execution for the NHL Predictor PoC and future AI-native projects.

The goal is to build upon the strong foundations already in place, enhancing the system to be more seamless, automated, repeatable, and auditable.

---

# ğŸ”¢ Why Are We Enhancing the Framework?

(... unchanged ...)


---

# âœ¨ Future State Vision

(... unchanged ...)


---

# ğŸ”§ Prioritized Implementation Backlog

The implementation will proceed in **batches**, aligned with the AI-native SDLC phases. After each batch, we will test using the NHL Predictor PoC to ensure the model enhancements are functioning as intended.


## ğŸ”¹ Batch 1: Project Initialization Phase

| Step | Action |
|:-----|:------|
| 1.1 | Implement `/project/init_project` route and logic |
| 1.2 | Create `scripts/structure_repo.py` to scaffold repo |
| 1.3 | Capture and auto-commit initial prompt and reasoning |
| 1.4 | Initialize memory.yaml links for project context |
| 1.5 | Update system prompt for project init process |


## ğŸ”¹ Batch 2: Discovery Phase (Early Task Execution)

| Step | Action |
|:-----|:------|
| 2.1 | Implement `/tasks/activate` smart prompt fallback |
| 2.2 | Implement auto-capture of prompt_used.txt |
| 2.3 | Implement auto-capture of reasoning_trace.md |
| 2.4 | Implement `/tasks/append_chain_of_thought/{task_id}` |
| 2.5 | Implement `/tasks/auto_commit/{task_id}` functionality |
| 2.6 | Wire auto-commit into activate/create/clone routes |
| 2.7 | Begin wiring changelog updates into these tool handlers |


## ğŸ”¹ Batch 3: Development Phase (Ongoing Task Execution)

| Step | Action |
|:-----|:------|
| 3.1 | Implement `/tasks/update_metadata/{task_id}` auto-commit |
| 3.2 | Implement `/tasks/clone` auto-commit |
| 3.3 | Enable auto-save of interim deliverables (designs, docs) |
| 3.4 | Auto-update chain of thought during development cycles |
| 3.5 | Continue wiring changelog updates for all dev actions |


## ğŸ”¹ Batch 4: Testing Phase (E2E Task Execution)

| Step | Action |
|:-----|:------|
| 4.1 | Implement `/memory/index` auto-commit |
| 4.2 | Implement `/memory/add` auto-commit |
| 4.3 | Add test capture of e2e readiness in reasoning traces |
| 4.4 | Expand system prompts for e2e validation behaviors |
| 4.5 | Test full traceable task flows in NHL PoC |


## ğŸ”¹ Batch 5: Cutover and Go-Live Phase

| Step | Action |
|:-----|:------|
| 5.1 | Implement `/tasks/append_handoff_note/{task_id}` route |
| 5.2 | Formalize handoff notes per task on completion |
| 5.3 | Finalize full batch promote_patch with complete artifacts |
| 5.4 | Validate CHANGELOG.md end-to-end capture |
| 5.5 | Validate memory.yaml coherence |
| 5.6 | Publish final NHL Predictor PoC app and system audit trail |


## ğŸ”¹ Batch 6: Final System Polish and Hardening

| Step | Action |
|:-----|:------|
| 6.1 | Define rollback strategy for failed batch deployments |
| 6.2 | Integrate metrics instrumentation into reasoning traces |
| 6.3 | Create short Human Lead onboarding guide for new flows |
| 6.4 | Explore multi-Pod orchestration options (stretch goal) |
| 6.5 | Auto-capture initialization Chain of Thought during init_project |
| 6.6 | Auto-link project context into memory.yaml (`project_init_trace`) |
| 6.7 | Enrich project initialization reasoning_trace.md to full format |

---

# ğŸ”§ Thoughts and Confirmations

âœ… This model will:
- Implement foundational enhancements progressively.
- Test practical flows after each major functional upgrade.
- Deliver both the framework AND the NHL PoC app working seamlessly.

âœ… Every major SDLC phase will be tested and verified before moving forward.

âœ… Risk is minimized by validating at each phase rather than all at once.


# ğŸš€ Working Approach

Each batch will be implemented using this workflow:
1. Human Lead says "Start next batch."
2. GPT provides overview: changes, outcomes, required inputs/files, assumptions.
3. Human Lead provides inputs/files.
4. GPT generates and prints patches.
5. Human Lead applies patches, tests, and reports back.

This ensures clear communication, clean implementation, and real-world validation.


# ğŸ“¦ Updated Batch 1: Project Initialization Phase â€” Kickoff

## ğŸ“Š Overview of Changes

We are implementing the project initialization foundation so that:

- A new project repo can be instantly scaffolded.
- Initial project metadata (prompt, reasoning) is captured.
- Git auto-commit happens after initializing core files (`task.yaml`, `memory.yaml`).
- We set up a clean, repeatable project structure.
- Ensure both `/framework/` and `/project/` directories exist.
- Copy required `/framework/` files into `/project/` to bootstrap the new repo correctly.

## ğŸ¯ Why Are We Doing This?

- Eliminate manual repo setup.
- Ensure every project starts with full traceability and full system capabilities.
- Accelerate project boot-up time.
- Ensure all future Pods are operating from a standardized, ready repo.

## ğŸŒŸ Outcomes Expected

- `/project/init_project` FastAPI route fully functional.
- Repo scaffold with `/framework/`, `/project/outputs/`, `/scripts/`, `/templates/`.
- Framework files copied to project repo as needed.
- Initial `task.yaml` and `memory.yaml` created (or verified).
- Initial reasoning trace and prompt captured and committed.
- Repo state is clean, organized, and ready for Discovery tasks.

## ğŸ—‚ï¸ Existing Files Needed

To implement Batch 1, I will need from you:

- âœ… `main.py` (current FastAPI server code â€” you uploaded earlier)
- âœ… `openapi.json` (current schema â€” uploaded earlier)
- ğŸ“‚ Template folder structure you want (or confirm "use default"):
  - `/framework/`
  - `/project/outputs/`
  - `/scripts/`
  - `/templates/`
- ğŸ“‹ Template `task.yaml` and `memory.yaml` to use if none exist (or say "draft starter templates")
- ğŸ“œ Baseline system prompt text for project initialization (or say "draft starter prompt")

## ğŸ“œ Assumptions

- We are working inside a GitHub repo already created externally.
- API has access to PyGitHub authenticated client.
- Repo permissions allow file creation and commits.
- If `/framework/` folder is missing, `/project/init_project` will halt and warn.
- Default framework files will be copied automatically to the `/project/` side for starting point if missing.
- No need for immediate pull request on init â€” just commit directly to `chatgpt/auto/init_project`.

## ğŸ›ï¸ Ready for you to:

âœ… Confirm or upload:

1. Template folder structure (or "use default")
2. Starter `task.yaml` and `memory.yaml` (or "draft starter")
3. Project init system prompt (or "draft starter")

Then, I'll generate the patches! ğŸš€

When you're ready, just reply with your inputs! ğŸ¯


# ğŸ“£ Batch 1 Kickoff â€” Initialize the Project

## ğŸ Overview

In this batch, we will implement end-to-end project initialization so that:

- We can cleanly initialize a new project repo.
- We copy required framework baseline files into the project folder structure.
- We capture initial project metadata (context, goals, strategy).
- We commit the initialized structure to GitHub under a clean branch (`chatgpt/auto/init_project`).

This is the very first step before we can kick off any SDLC tasks (Discovery, Development, Testing, Go-live).

## ğŸ—ï¸ Changes to Implement

| Change | Why |
| :--- | :--- |
| `/project/init_project` FastAPI route | To orchestrate project setup |
| Repo renaming (`ai-delivery-framework` â†’ `ai-delivery-framework`) | To accurately reflect that it's the framework |
| Create new repo for NHL Predictor app | Separation of framework vs project |
| Auto-copy `/framework/` files if missing | Ensure project starts with full framework baseline |
| Initialize clean `/project/` folder | Structure organized clearly |
| Create starter `task.yaml`, `memory.yaml` from provided templates | Enable task tracking |
| Draft and store initialization prompt | Capture "Why are we starting this project?" |
| Draft and store initialization reasoning trace | Capture "How was this set up?" |
| Commit changes to GitHub | Full traceability of initial setup |

## ğŸ“„ Files You Provided (âœ…)

- `main.py` (FastAPI backend)
- `openapi.json` (Custom GPT tool schema)
- `task.yaml` (Standard task template)
- `memory_stub.yaml` (Memory starter)

âœ… This covers everything needed for the coding!

## âœï¸ Starter Prompt for Project Initialization

ğŸ§  **Project Initialization Prompt: NHL Playoff Predictor PoC**

**Context**: We are building an AI-native NHL Playoff Predictor application as a Proof of Concept.  
**Objective**: Capture project goals, flows, architecture, experiments, and delivery traceability using the AI Delivery Framework.  
**Scope**: Start from Discovery (defining goals and user flows), through Development (building features), into E2E Testing and Go-live.  
**Pods Involved**: DevPod, QAPod, DeliveryPod, WoWPod, Human Lead.  
**Deliverable**: A working AI application + proof of enhanced AI-native delivery methods.

## ğŸ”µ Assumptions (âœ… Confirmed)

| Assumption | Status |
| :--- | :--- |
| Repo already exists for Framework (`ai-delivery-framework`) | âœ… Yes (will rename) |
| Repo exists or will create new for NHL Predictor | âœ… New repo needed |
| PyGitHub token available and working | âœ… Confirmed |
| Permissions to create files/commit | âœ… Confirmed |
| `/framework/` folder is mandatory for setup | âœ… Yes |
| Default framework files copied if missing | âœ… Yes |
| No pull request needed on init (direct commit) | âœ… Yes |

## ğŸ› ï¸ Next Steps â€” Batch 1 Coding Plan

Now that you provided everything:

âœ… **Step 1**: I will generate a new `/project/init_project` FastAPI route.  
âœ… **Step 2**: It will:
- Check and copy framework files
- Create the `/project/` baseline
- Store `task.yaml`, `memory.yaml`, initial prompt and reasoning
- Auto-commit to `chatgpt/auto/init_project`
âœ… **Step 3**: I'll show you the patches to apply.

## âš¡ Quick Recap: Why Do It This Way?

| Reason | Outcome |
| :--- | :--- |
| Eliminate manual repo setup | Faster start for all projects |
| Standardize structure | Fewer mistakes, easier scaling |
| Capture project context from the beginning | Full traceability |
| Automate commit history | Trustable source of truth |
| Clean framework vs project separation | Maintainable for long term |

## âœ… Ready to Start Batch 1?

If yes, I'll proceed to:

- Start generating the `/project/init_project` route
- Print code patches for you
- Hand over for you to apply and test ğŸ¯

# âœï¸ Summary of New FastAPI Route

## POST `/project/init_project`

### ğŸ“¥ Inputs

- `repo_name`: Name of GitHub repo to initialize (string)
- `project_name`: Name for project folder under `/project/` (string)
- `project_description`: Human-readable description (string)

### âš™ï¸ Actions

- Validate `/framework/` folder exists in the repo.
- Create `/project/{project_name}/` structure:
  - `outputs/`
  - `scripts/`
  - `templates/`
- Copy necessary `/framework/` templates/files into project side.
- Create starter `task.yaml`, `memory.yaml` if missing.
- Capture project initialization prompt and reasoning trace.
- Auto-commit all changes to `chatgpt/auto/init_project` branch.


# ğŸ› ï¸ 2. Manual Actions Outside Code

To fully implement Batch 1 successfully, you will need to:

| Task | Notes |
| :--- | :--- |
| Rename the `ai-concussion-agent` repo â†’ `ai-delivery-framework` | This will officially establish it as the framework repo |
| Create new repo: `nhl-predictor` (or similar) | This will be the PoC project repo |
| Confirm both repos have `/framework/` folder | It must exist and have baseline templates |
| Confirm GitHub PAT has access to new repos | (Should be true if using the same token) |
| After repo rename, adjust any hardcoded repo names if needed | (We'll check together if needed after rename) |

# ğŸ“‹ 3. Whatâ€™s Left for Full Project Initialization (per Future State Vision)

| Item | Status | Planned Batch |
| :--- | :--- | :--- |
| Auto-capture initialization Chain of Thought | âŒ Not done yet | Batch 2 (Discovery Phase Enhancements) |
| Auto-capture `reasoning_trace.md` during project init | âœ… Simple version done (expand later) | Expand in Batch 2 |
| `memory.yaml` linking to project context (`project_init_trace`) | âŒ Not yet | Batch 2 |
| Auto-commit to a structured branch (`chatgpt/auto/init_project`) | âœ… Done |  |
| Create human onboarding prompt/template for new project | âŒ Future optional | Batch 6 (System Polish) |
| Add rollback strategy if init fails mid-way | âŒ Future optional | Batch 6 (System Polish) |

# âœ… Quick Recap

- Batch 1 covers basic project setup and framework copying.
- Minor auto-capture (prompt, reasoning) already done in basic form.
- We'll enrich traceability (Chain of Thought, project context links) in **Batch 2** and polish further in **Batch 6**.


# ğŸ”¢ Folder Restructuring Plan for Framework and PoC Projects

## ğŸ“‚ Framework Repo (`ai-delivery-framework`)

| Folder | Purpose |
| :--- | :--- |
| `/framework/` | Core templates, reusable system files (extracted from `task_templates`, `prompts`, `scripts`) |
| `/docs/` | System overview, operations, guides, roadmap |
| `/scripts/` | Shared automation scripts (e.g., `generate_patch`, `init_repo`) |
| `/prompts/` | Templates and archives of used prompts |
| `/task_templates/` | Task blueprints organized by SDLC phase |
| `/` (root files) | `main.py`, `openapi.json`, `requirements.txt`, `task.yaml` (template), `memory.yaml` (stub), `README.md`, `.env`, `.gitignore` |

---

## ğŸ“‚ PoC Project Repo (`nhl-predictor`)

| Folder | Purpose |
| :--- | :--- |
| `/project/data/` | Raw input data, datasets, seed files |
| `/project/notebooks/` | Jupyter notebooks for analysis, prototyping |
| `/project/outputs/` | Task outputs (`prompt_used`, `reasoning_traces`, `handoff notes`) |
| `/project/src/client/` | Frontend code (UI) |
| `/project/src/server/` | Backend server code (APIs) |
| `/project/src/utils/` | Shared utilities/helpers |
| `/project/src/scripts/` | Batch job scripts, CLI tools |
| `/project/docs/` | Project-specific documentation, API docs |
| `/project/logs/` | System logs, debugging outputs |
| `/project/test/` | Unit tests, integration tests |
| `/framework/` | (Copied from framework baseline at init) |
| `/` (root files) | `README.md`, `task.yaml`, `memory.yaml`, `.gitignore` |

---

### ğŸ”µ Notes

- `/framework/` in PoC repo will be **static copies** â€” refreshed manually if needed.
- `/project/` contains **active, growing project-specific work products**.

---

# ğŸ”¹ Bash Script for Repo Rename and New Repo Creation

```bash
#!/bin/bash

# Rename existing repo (manual via GitHub Web UI advised)
echo "Please manually rename 'ai-delivery-framework' to 'ai-delivery-framework' via GitHub settings."
echo "\nWaiting 10 seconds for you to complete..."
sleep 10

# Create new PoC repo
NEW_REPO_NAME="nhl-predictor"
USER="stewmckendry"

# Use GitHub CLI (gh) to create repo
if gh repo view $USER/$NEW_REPO_NAME > /dev/null 2>&1; then
  echo "Repo $NEW_REPO_NAME already exists. Skipping creation."
else
  echo "Creating new repo: $NEW_REPO_NAME"
  gh repo create $USER/$NEW_REPO_NAME --public --confirm
fi

# Clone locally if needed
echo "\nTo clone locally:"
echo "git clone https://github.com/$USER/$NEW_REPO_NAME.git"

```

âœ… Save as: `scripts/init_repos.sh`
âœ… Make executable: `chmod +x scripts/init_repos.sh`

(Note: Assumes you have `gh` (GitHub CLI) installed and authenticated.)


---

# ğŸš€ Ready to proceed!

Now you can:
- Apply openapi.json patch
- Run repo rename and setup
- Test `/project/init_project`

Then report back for results and next steps!

---

# ğŸ“‚ Framework Copy Guidelines

## Should It Be in `/framework/`?

| Should It Be in `/framework/`? | Type of File | Rule |
| :--- | :--- | :--- |
| âœ… Yes | Templates, reusable task packs, prompt templates, memory stubs, core shared scripts | Reusable assets meant to start any project |
| âœ… Yes | API/Plugin Integration Prompts | Prompts that power tooling (`gpt_tools` prompts) |
| âŒ No | Project-specific data, outputs, logs, test results | Tied to a specific project or PoC |
| âŒ No | POC-specific README, project-specific prompts | Only move generalized docs, not project deliverables |
| âŒ No | `.logs/`, `.gitkeep`, `.DS_Store` | Internal build artifacts or MacOS noise files |
| âŒ No | ChatGPT repo outputs, patch zips | Deliverable outputs specific to PoC sessions |
| âŒ No | Test data, project-specific notebooks/scripts | Stay in project repos like `nhl-predictor/` |

---

## ğŸ“‹ Specific Examples from Your File List

| File(s) | Action |
| :--- | :--- |
| `/task_templates/Phase*/` folders | âœ… Copy to `/framework/task_templates/` |
| `/prompts/gpt_tools/*.txt` | âœ… Copy to `/framework/prompts/gpt_tools/` |
| `/scripts/generate_patch_from_output.sh`, `promote_patch.sh`, `init_repo.sh` | âœ… Copy to `/framework/scripts/` |
| `/memory_stub.yaml` | âœ… Copy to `/framework/memory.yaml` |
| `/task.yaml` (framework version) | âœ… Copy to `/framework/task.yaml` |
| `/main.py`, `/openapi.json`, `/requirements.txt` | âŒ Stays at repo root â€” needed for FastAPI app, not per-project |
| `/docs/overview/*.md` | âœ… Copy useful overview docs into `/framework/docs/overview/` |
| `/docs/system/*.md` | âœ… Copy system-level documents to `/framework/docs/system/` |
| `/docs/roadmap/*.md` | âœ… Copy into `/framework/docs/roadmap/` |
| `/docs/guides/*.md` | âœ… Copy onboarding/setup guides to `/framework/docs/guides/` |
| `/project1_nhl_poc/`, `/test_data/`, `/poc/test_cases/` | âŒ These are project-specific: DO NOT move into framework |
| `/poc/ChatGPT_Git/*.md` test result files | âŒ Stay archived separately if you want (not framework) |
| `.logs/`, `chatgpt_repo/outputs/`, `.DS_Store` | âŒ Ignore â€” don't copy to framework |

---

# ğŸš€ In Short:

- âœ… Framework is for **starting any future project fast and clean**.
- âœ… Project-specific deliverables and test data **stay out of the framework repo**.

---

# ğŸ“‚ Updated Visual of Framework Folder after Organizing

```
framework/
â”œâ”€â”€ task_templates/
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ gpt_tools/
â”œâ”€â”€ scripts/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ overview/
â”‚   â”œâ”€â”€ guides/
â”‚   â”œâ”€â”€ roadmap/
â”‚   â””â”€â”€ system/
â”œâ”€â”€ memory.yaml
â”œâ”€â”€ task.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
```

---

# ğŸ›ï¸ Reminder

When you run `/project/init_project`, it copies this `/framework/` into the new project repo under `/framework/` automatically â€” ready for the Pod to get working.

# ğŸ› ï¸ Update on Batch 1 Progress

## âœ… Whatâ€™s Completed

1. Renamed `ai-concussion-agent` repo to `ai-delivery-framework`, synced with local repo, and updated file references.
2. Re-organized files in `ai-delivery-framework` per the new repo structure.
3. Ran `init_repo.sh` to create new `nhl-predictor` GitHub repo.

---

# ğŸ› ï¸ 1. Setup Local Folder for New NHL Predictor Repo

Now that the `nhl-predictor` repo is created on GitHub, you should:

```bash
# Navigate to your projects folder
cd /Users/liammckendry/Projects/

# Create project standard folders
mkdir -p project/data
mkdir -p project/notebooks
mkdir -p project/outputs/project_init
mkdir -p project/src/client
mkdir -p project/src/server
mkdir -p project/src/utils
mkdir -p project/src/scripts
mkdir -p project/docs
mkdir -p project/logs
mkdir -p project/test

# Also create empty /framework/ folder to be filled later by /project/init_project
mkdir -p framework

# Touch basic placeholder files if necessary
touch project/outputs/.gitkeep

# Clone the new repo
git clone https://github.com/stewmckendry/nhl-predictor.git

# Move into the project folder
cd nhl-predictor
```

âœ… You should now have a clean, empty `nhl-predictor/` project folder locally â€” ready for `/project/init_project`.

---

# ğŸ”¥ 2. What You Still Need to Do to Complete Batch 1

| Step | Description |
| :--- | :--- |
| Confirm local clone is clean | `git status` inside `nhl-predictor/` should show a clean, empty repo |
| Run `/project/init_project` via your FastAPI app | Inputs:<br>- `repo_name='nhl-predictor'`<br>- `project_name='NHL Predictor'`<br>- `project_description='Proof of concept NHL playoff outcome predictor.'` |
| Verify post-init project structure | Check that `/framework/`, `/project/outputs/`, `/project/scripts/`, etc., were properly created |
| Verify auto-commit happened | Check GitHub: repo should have a new commit (`chatgpt/auto/init_project` branch or similar) with init files |
| Confirm reasoning trace + prompt_used.txt | Check `/project/outputs/project_init/` for generated trace files |
| Manual review | - Framework files copied âœ”ï¸<br>- Project folders created âœ”ï¸<br>- Minor files like `memory.yaml`, `task.yaml` are present âœ”ï¸ |

---

# ğŸ“‹ Quick Validation Checklist

| Item | Expected Outcome |
| :--- | :--- |
| Repo cloned locally | âœ… |
| `/framework/` copied into repo | âœ… |
| `/project/outputs/`, `/scripts/`, `/templates/` created | âœ… |
| `task.yaml` and `memory.yaml` exist at project root | âœ… |
| `prompt_used.txt` and `reasoning_trace.md` generated in `outputs/project_init/` | âœ… |
| GitHub commit created with init changes | âœ… |

---

# âš¡ Quick Reminder

âœ… **Batch 1** covers:
- Initial project setup
- Framework copy
- Auto-initial commit

âŒ **Deferred to later batches**:
- Chain of Thought enrichment
- Project context linking to `memory.yaml`
- Deeper Discovery phase artifacts

---

# ğŸ› ï¸ FAQs About `/project/init_project`

---

## 1. Which Repo Does `/project/init_project` Affect?

âœ… **Answer**: It creates files/folders inside the `nhl-predictor` repo.

- Even though the FastAPI app (`main.py`) lives in the `ai-delivery-framework` repo, it is programmed to operate on the project repo based on the `repo_name` or `project_path` you pass.
- Think of `ai-delivery-framework` as the **"central brain"** managing multiple projects.

---

## 2. Where Should `main.py` and `openapi.json` Live?

âœ… **Answer**: They stay in the `ai-delivery-framework` repo.

- `ai-delivery-framework` is your **core platform**.
- It holds all:
  - FastAPI routes
  - Framework templates
  - System prompts
  - Future tools
- Project repos like `nhl-predictor/` stay **very clean and lightweight** â€” only project-specific files, **no FastAPI app**, **no OpenAPI spec** inside them.

---

## 3. How Do You Call `/project/init_project`?

âœ… **Answer**: You call `/project/init_project` from a **Custom GPT** (like DeliveryPod) or manually.

- **Update your GPTâ€™s** `openapi.json` schema to include the `/project/init_project` route if not already done.
- Alternatively, **manually** call it using:
  - `curl`
  - Postman
  - Swagger UI (e.g., [http://localhost:8000/docs](http://localhost:8000/docs) if running FastAPI locally)

---

## 4. Starter Prompt for GPT to Initiate the Project

âœ… **Hereâ€™s a clean starter prompt:**

### ğŸš€ Starter Prompt for DeliveryPod

> ğŸ¯ **POD MISSION: Initialize a New Project Repository**  
> We are kicking off a new AI-Native Delivery project.
> 
> **Project Name**: NHL Predictor  
> **Repository Name**: nhl-predictor  
> **Project Description**: Proof of concept NHL playoff outcome predictor.
>
> **ğŸ› ï¸ Instructions:**
> - Call the `/project/init_project` endpoint.
> - Pass the fields:
>   - `repo_name = 'nhl-predictor'`
>   - `project_name = 'NHL Predictor'`
>   - `project_description = 'Proof of concept NHL playoff outcome predictor.'`
> - After initialization, confirm:
>   - `/framework/` folder has been copied.
>   - `/project/` folders (`outputs`, `scripts`, etc.) exist.
>   - `task.yaml` and `memory.yaml` are present.
>   - `prompt_used.txt` and `reasoning_trace.md` are created under `/project/outputs/project_init/`.

ğŸš€ **Goal**: Setup a fully initialized project workspace ready for AI-native delivery.

---

# ğŸ“‹ Recap of Confirmations

| Topic | Answer |
| :--- | :--- |
| Which repo gets init? | `nhl-predictor` |
| Where does `main.py` live? | `ai-delivery-framework` |
| Where is `openapi.json` updated? | `ai-delivery-framework` |
| Who calls init? | DeliveryPod GPT or manual API test |
| Is starter prompt ready? | âœ… Yes â€” see above |

---

# ğŸš€ Final Prep Before Running `/project/init_project`

- âœ… `openapi.json` updated
- âœ… FastAPI server running (if manual)
- âœ… GPT custom action added (if via GPT)

ğŸ¯ **Youâ€™re ready to fire `/project/init_project`!**


# ğŸ“š Full Correct Assumptions

| Item | Status |
| :--- | :--- |
| A new repo is created per delivery project | âœ… Yes |
| Each repo is initialized at the start using `/project/init_project` | âœ… Yes |
| `/project/init_project` sets up baseline files and structure | âœ… Yes |
| After init, GPT Pods and Human Lead start Phase 1 tasks immediately | âœ… Yes |
| `framework/` folder copied in so each project is semi-standalone but shares standard tooling | âœ… Yes |
| No `/project/NHL Predictor/` needed â€” all project files live at root level | âœ… Yes |

---

# ğŸ§  Why This Model is Great

| Benefit | Impact |
| :--- | :--- |
| Clean scaling | 1 repo = 1 project = 1 AI-native lifecycle |
| Easy handoff | Each project repo is self-contained |
| Easy archiving or audits later | Just freeze repo snapshot |
| Easy upgrades | Framework patches can be merged if needed |

âœ… It's clean, simple, and scales even as the number of delivery projects grows.

---

# ğŸ“‹ Therefore Final Answer

âœ… **Yes**, youâ€™re supposed to run `/project/init_project` at the start of every delivery project.  
âœ… **Yes**, each project lives in its own GitHub repo.  
âœ… **Yes**, the outputs (`task.yaml`, `memory.yaml`, `outputs/`, etc.) should be at the **repo root** â€” no `/project/NHL Predictor/` nesting.


